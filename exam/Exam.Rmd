---
title: "Exam Part 1"
subtitle: "Age Specific Fertility Ratio for Spain, years 1922 to 2018."
author: "Alexander J Ohrt"
date: "`r format(Sys.time(), '%d/%b/%Y')`"
output: 
   html_document:
    code_folding: hide
    theme: cerulean
    highlight: textmate
    number_sections: true
    toc: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "#>")
library(ggplot2)
library(dplyr)
library(stops)
library(plot3D)
library(princurve)
```


```{r}
set.seed(1234)
load('ASFR_exam_2022.Rdata')
dim(ASFR)

image(Year,Age,ASFR, col=hcl.colors(24, "YlOrRd", rev = TRUE))
abline(v=seq(1920,2020,by=10),col=8)

some.years <- c(1, 34, 64, 97)
matplot(Age,t(ASFR[some.years,]),col=c(1,2,3,4), type="l", lwd=2, lty=1,
ylab="ASFR", main="ASFR for several years as a function of mother age")
abline(v=seq(20,50,by=10),col=8,lty=2)
abline(h=0,col=8)
legend("topright",legend=Year[some.years],col=c(1,2,3,4), lwd=2)
```

# Principal Component Analysis of ASFR

```{r}
pce <- princomp(ASFR)

eigvals <- pce$sdev^2
pctg.VE <- 100*eigvals/sum(eigvals)
cum.pctg.VE <- cumsum(pctg.VE)
cum.pctg.VE[1:10]
```

The percentage of variance explained by each of the 10 first PC's is shown above. A scatterplot of the scores of the first two PCs is shown below. 

```{r}
df <- data.frame(Comp1 = pce$scores[,1], Comp2 = pce$scores[,2], label = factor(Year))
df %>% ggplot(aes(x = Comp1, y = Comp2, label = label)) + 
   geom_point() +
   geom_text(hjust=0, vjust=0) + 
   theme_minimal()
```

I think the true dimensionality of this data is 3, since 3 components explains alomst all the variation in the data. Moreover, based on the plots shown earlier (the graphical representations given), it seems reasonable that the data could have dimension 3, with the 3 dimensions simply being "Age", "Year" and "ASFR" (the value itself.)

# Local MDS for dimensionality reduction to dimension $q = 1$

## Choose tuning parameter $K$ to according to the Local Continuity Meta-Criteria. 

We re-use a bunch of code from lecture notes. Shown in code block below. 

```{r}
# Local MDS. Implemented by Pedro Delicado, December 2020
#
# Objective function in Local MDS, eq (7) in Chen and Buja (2009)
Stress.LocalMDS <- function(conf,dist.orig,k=5,tau=1){
  require(smacof)
  ld <- length(dist.orig)
  n <- (1+sqrt(1+8*ld))/2
  q<-length(conf)/n
  mconf <- matrix(conf,nrow = n, byrow = FALSE) # configuration matrix
  Eucl.dist <- dist(mconf)
  w <- dissWeights(dist.orig, type = "knn", k = k)
  w.1 <- (w==1)
  card.N.k <- sum(w.1)
  card.N.k.c <- n*(n-1)/2 - card.N.k
  t <- (card.N.k/card.N.k.c)*median(dist.orig[w.1])*tau
  return(sum((dist.orig[w.1]-Eucl.dist[w.1])^2) - t*sum(Eucl.dist[!w.1]))
}

LocalMDS <- function(dist.orig,k=5,tau=1,q=2, maxit=1000){
  # dist.orig: Distance matrix (as a dist object) in the high-dim space 
  # k: Neighbors defining the N_k set of nearby pairs
  # tau: weight of the large distances part of the Stress function
  # q: Dimension of the low-dimensional configuration
  # maxit: Maximum number of iteration in the optim function
  conf0 <- as.numeric(stats::cmdscale(dist.orig,k=q, list. = F))
  n <-length(conf0)/q
  localMDS.res <- optim(par=conf0, fn=Stress.LocalMDS,
                          dist.orig=dist.orig, k=k, tau=tau,
                          method ="BFGS", control = list(maxit=maxit))
  conf.localMDS.res <- matrix(localMDS.res$par, nrow = n, byrow = FALSE)
  return(conf.localMDS.res)
}

# Take this function from the lecture material. Used to calculate Local Cont. Meta-Criteria. 
LCMC <- function(D1,D2,Kp){
  D1 <- as.matrix(D1)
  D2 <- as.matrix(D2)
  n <- dim(D1)[1]
  N.Kp.i <- numeric(n)
  for (i in 1:n){
    N1.i <- sort.int(D1[i,],index.return = TRUE)$ix[1:Kp]
    N2.i <- sort.int(D2[i,],index.return = TRUE)$ix[1:Kp]
    N.Kp.i[i] <- length(intersect(N1.i, N2.i))
  }
  N.Kp<-mean(N.Kp.i)
  M.Kp.adj <- N.Kp/Kp - Kp/(n-1)
  
  return(list(N.Kp.i=N.Kp.i, M.Kp.adj=M.Kp.adj))
}
```


```{r, cache=T}
q <- 1
k <- 5
tau <- 0.5
delta <- dist(ASFR) # Calculate a distance matrix for ASFR. 


Kp <- 10
k.search <- c(5,10,15)
nk <- length(k.search)

LC <- matrix(0,nrow=nk)
LocalMDS.k <- array(vector("list",1),dim=dim(LC))

for (i in 1:nk){
  LocalMDS.k[[i]] <- LocalMDS(delta, k=k.search[i], tau=tau,q=q, maxit=20)
  D2.k <- dist(LocalMDS.k[[i]])
  LC[i] <- LCMC(delta,D2.k,Kp)$M.Kp.adj
}

i.max <- which.max(LC)
k.max <- k.search[i.max]

print(paste0("k.max = ",k.max))

lmds.max <- LocalMDS.k[i.max][[1]]

plot(k.search, LC, type="b", main=paste0("k.max=",round(k.max,4)))
abline(v=k.max,col=2)
```

The results above clearly show that $K = 5$ gives the best results according to the criteria. We plot the scores in the underlying dimension as a function of `Year`.

```{r}
plot(Year, lmds.max)
```

From the plot above we can see that the scores of the local MDS with the optimal $K$ look to be almost linear as a function of `Year` - increasing. 

## Give a graphical representation of the Local MDS output and comment on the obtained results

```{r}
grp.indices <- quantile(lmds.max, c(0.25, 0.5, 0.75))
group1.ind <- lmds.max < grp.indices[1]
Group1 <- lmds.max[group1.ind]

group2.ind <- (lmds.max < grp.indices[2] & lmds.max >= grp.indices[1])
Group2 <- lmds.max[group2.ind]

group3.ind <- (lmds.max < grp.indices[3] & lmds.max >= grp.indices[2])
Group3 <- lmds.max[group3.ind]

group4.ind <- lmds.max >= grp.indices[3]
Group4 <- lmds.max[group4.ind]

average.ASFR.1 <- mean(ASFR[group1.ind, ])
average.ASFR.2 <- mean(ASFR[group2.ind, ])
average.ASFR.3 <- mean(ASFR[group3.ind, ])
average.ASFR.4 <- mean(ASFR[group4.ind, ])

# No more time here. 
par(mfrow = c(2,2))
#plot(12:55,average.ASFR.1,main = "Group1")
#plot(average.ASFR[group2.ind], main = "Group2")
#plot(average.ASFR[group3.ind], main = "Group3")
#plot(average.ASFR[group4.ind], main = "Group4")
par(mfrow = c(1,1))
```

It looks like ... (I have no more time)

## Representing the Local MDS output on the plane of the 2 first PCs

(No more time unfortunately :( ) 

```{r, eval = F}
plot()
```


# Non-linear dimensionality reduction in the space of $\textit{Motherâ€™s age}$.

```{r}
V <- pce$loadings
W <- t(apply(V^2,1,cumsum))
matplot(t(W),type="l")
```

## MDS on matrix W

```{r}
delta2 <- dist(W)
mds2 <- stats::cmdscale(delta2,k=3, eig = T)
mds2$GOF

cumsum(mds2$eig[1:3])/sum(pmax(mds2$eig,0))*100
cumsum(mds2$eig[1:3])/sum(abs(mds2$eig))*100
```

The quality of the 3-dimensional representation of the rows of $W$ is given above. Depending on the measure we want to use - when summing over the eigenvalues one can choose to divide by either the absolute value of all eigenvalues or only divide by the eigenvalues that are positive. The output from `mds$GOD` shows both these things, in the mentioned order. They are both the same since we do not have any negative eigenvalues here. For the same reason, the two calculated cumulative sums above, in the same order as explained when it comes to method, are equal. The cumulative sum recovers $\approx 95\%$ of the variance in the data, which I would regard as a good quality representation of the data, because we have been able to largely reduce the dimensionality, while not losing a lot of information. 

The representation in 2 dimensions is shown below. 

```{r}
pairs(mds2$points)
```

A 3-dimensional plot is shown below. 

```{r}
points3D(mds2$points[,1], mds2$points[,2], mds2$points[,3],
         xlab = "Dim1", ylab = "Dim2", zlab ="Dim2", col = 2, 
         phi = 20, theta = 60, lwd=4,as=1)
```

It seems like the real underlying dimensionality of the rows in $W$ might be 3, since this representation recovers such a large part of the variability in the data and while keeping what we learned earlier in mind. 

## Fit a principal curve to the MDS output

We fit a principal curve to the 3-dimensional configuration obtained by MDS, with the given parameters in the R function. 

```{r}
princ.curve <- principal_curve(mds2$points, smoother = "lowess", f = 0.1)
```

We compare the 1-dimensional representation obtained with the age of the mother. A graphical comparison is done below, via a scatter plot.

```{r}
plot(12:55,princ.curve$lambda)
```

We can see that the 1-dimensional representation follows what resembles an upside down U, i.e. a $-x^2$, as a function of the mother's age (it is not a mathematical function, I am simply commenting on the shape of it). 

## 3-dim representation of the principal curve

The principal curve is shown over the 3-dimensional scatterplot of the output from MDS. It is shown from several different angles. 

```{r}
points3D(mds2$points[,1], mds2$points[,2], mds2$points[,3],
         xlab = "Dim1", ylab = "Dim2", zlab ="Dim2", col = 2, 
         phi = 20, theta = 60, lwd=4,as=1)
lines3D(princ.curve$s[, 1], princ.curve$s[, 2], princ.curve$s[, 3], add = T, 
        phi = 20, theta = 60, lwd=4,as=1, colvar = F)

points3D(mds2$points[,1], mds2$points[,2], mds2$points[,3],
         xlab = "Dim1", ylab = "Dim2", zlab ="Dim2", col = 2, 
         lwd=4,as=1)
lines3D(princ.curve$s[, 1], princ.curve$s[, 2], princ.curve$s[, 3], add = T, 
        lwd=4,as=1, colvar = F)

points3D(mds2$points[,1], mds2$points[,2], mds2$points[,3],
         xlab = "Dim1", ylab = "Dim2", zlab ="Dim2", col = 2, 
         phi = 10, theta = 30, lwd=4,as=1)
lines3D(princ.curve$s[, 1], princ.curve$s[, 2], princ.curve$s[, 3], add = T, 
        phi = 10, theta = 30, lwd=4,as=1, colvar = F)
```

It looks like the principal curve has fitted the data-output from the MDS quite well.
