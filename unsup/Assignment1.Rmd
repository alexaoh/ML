---
title: "Assignment 1"
subtitle: "Density Estimation and Clustering"
author: "Alexander, Ulrik, Hannes"
date: "`r format(Sys.time(), '%d/%b/%Y')`"
output: 
   html_document:
    code_folding: hide
    theme: cerulean
    highlight: textmate
    number_sections: false
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "#>")
library(sm)
library(ggplot2)
library(dplyr)
```

# Load Boston Housing Data

```{r}
data("Boston", package = "MASS")
X <- scale(Boston[,c(13,6)])
plot(X,as=1)
```

# Questions

## 1. Estimate Joint Bivariate Density

We want to estimate the joint bivariate density using a kernel estimator with the same bandwidth in both dimensions: $h = (a, a)$. The maximum log-likelihood cross-validation method will be used to choose the value of $a$. Then, the density will be estimated using this value of $a$. Some level curves of this estimated density are plotted below. 

```{r}
# Valid choice of a
a.domain <- seq(0.1, 1, by = 0.1)

# Number of data points
n <- dim(X)[1]

# Create storage for the sample log-likelihoods
f.hat.cv <- matrix(0, nrow = length(a.domain))

# Iterate through a values
for (i in 1:length(a.domain)) {
  # Iterate over all data points
  for (j in 1:n) {
    # Remove data point j from the data 
    point.j <- matrix(X[j,], ncol = 2)
    X.j <- X[-j,]
    # Calculate the likelihood of x.j (with x.j left out)
    f.hat.j <- sm.density(X.j, h = a.domain[i]*c(1,1), display="none",
                          eval.grid = F, eval.points = point.j)$estimate
    # Add the logarithm of the estimate to the total log-likelihood
    f.hat.cv[i] <- f.hat.cv[i] + log(f.hat.j)
  }
}

# Maximum likelihood cross-validation value of a
a.ml <- a.domain[which.max(f.hat.cv)]

# Plotting the density estimation with our chosen a value
plot(X, as = 1, col = 8)
sm.density(X, h = a.ml*c(1,1), display = "slice",
           props = c(25,50,75,95), col = 2, add = T)
```

The optimal value on the discrete grid of $a$'s 

```{r}
a.domain
```

is `r a.ml`. 

## 2. Hierarchical Clustering

Hierarchical clustering using the **ward.D** method. The dendrogram is shown below. 

```{r}
hcl1 <- hclust(dist(X), method="ward.D") # Euclidean distance, ward.D method. 
plot(hcl1)
```

The dendrogram is cut into $k = 3$ clusters. The scatterplot below shows how the points are distributed in the three clusters. 

```{r}
clusts <- cutree(hcl1, 3)
df <- data.frame(lstat = X[,1], rm = X[,2], cluster = factor(clusts))
ggplot(df, aes(x = lstat, y = rm)) + 
   geom_point(aes(colour = cluster)) +
   theme_minimal()
```


## 3. For each of the Clusters, do ...

### Cluster 1

```{r}
# Data from cluster 1.
clust1.data <- df %>% dplyr::filter(cluster == "1")

# Non-parametric estimation of the joint density. 
plot(clust1.data[, c(1,2)])
sm.density(clust1.data[, c(1,2)], h = a.ml*c(1,1), display="slice",props=c(75),col=2,add=TRUE)
```

### Cluster 2

```{r}
# Data from cluster 1.
clust2.data <- df %>% dplyr::filter(cluster == "2")

# Non-parametric estimation of the joint density. 
plot(clust2.data[, c(1,2)])
sm.density(clust2.data[, c(1,2)], h = a.ml*c(1,1), display="slice",props=c(75),col="green",add=TRUE)
```

### Cluster 3

```{r}
# Data from cluster 1.
clust3.data <- df %>% dplyr::filter(cluster == "3")

# Non-parametric estimation of the joint density. 
plot(clust3.data[, c(1,2)])
sm.density(clust3.data[, c(1,2)], h = a.ml*c(1,1), display="slice",props=c(75),col="blue",add=TRUE)
```

### Combined Plot

The 75\% level curves of all three estimated densities are plotted below. 

```{r}
plot(X, as=1, col = 8)
sm.density(clust1.data[, c(1,2)], h = a.ml*c(1,1), display="slice",props=c(75),col=2,add=TRUE)
sm.density(clust2.data[, c(1,2)], h = a.ml*c(1,1), display="slice",props=c(75),col="green", add=TRUE)
sm.density(clust3.data[, c(1,2)], h = a.ml*c(1,1), display="slice",props=c(75),col="blue", add=TRUE)
```


## 4. Repeat 2 and 3, with Automatically Selected Optimal Number of Clusters

```{r}
# Dette kan fjernes. 
# Which of the following values should we trust?
h1 <- h.select(X, method = "cv")
h2 <- hcv(X, method = "cv")

# Density estimation using the value of a found above. 
plot(X,as=1, col = 8)
sm.density(X, h = h1[[1]]*c(1,1), display="slice",props=c(25,50,75,95),col=2,add=TRUE)
```

The optimal bandwidth is selected separately for each cluster. 
